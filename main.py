# main.py
import concurrent.futures
import time
import os
import sys
import shutil
from video_processor.splitter import split_video_to_audio_chunks
from video_processor.transcriber import transcribe_single_audio_chunk
from dify_api_text import run_workflow

def main_process_generator(video_path: str, openai_api_key: str, dify_api_key: str, output_filename: str):
    """
    ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œæ‰§è¡Œæ•´ä¸ªæµç¨‹å¹¶å®æ—¶ yield çŠ¶æ€å’Œè¿›åº¦ã€‚
    """
    # --- å‡†å¤‡å·¥ä½œ ---
    # æ ¹æ®ç”¨æˆ·è¾“å…¥åŠ¨æ€ç”Ÿæˆè¾“å‡ºè·¯å¾„
    output_dir = "output_chunks"
    transcript_save_path = "source_transcript.txt"
    final_notes_save_path = f"{output_filename}.md" # ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æ–‡ä»¶å

    total_steps = 4 # æ€»å…±æœ‰4ä¸ªä¸»è¦æ­¥éª¤
    current_progress = 0
    
    # --- æ­¥éª¤ 1: åˆ‡åˆ†è§†é¢‘ ---
    yield "progress", current_progress / total_steps, "æ­¥éª¤ 1/4: æ­£åœ¨åˆ‡åˆ†è§†é¢‘ä¸ºéŸ³é¢‘å—..."
    
    # å®šä¹‰ä¸€ä¸ªå›è°ƒå‡½æ•°æ¥æ›´æ–°ä¸»è¿›åº¦æ¡
    def split_progress_updater():
        # è¿™ä¸ªå‡½æ•°ä»€ä¹ˆä¹Ÿä¸ç”¨åšï¼Œæˆ‘ä»¬åªåˆ©ç”¨ as_completed æ¥é©±åŠ¨è¿›åº¦
        pass

    audio_chunks = split_video_to_audio_chunks(
        video_path=video_path,
        output_dir=output_dir,
        chunk_duration=600
        # è¿™é‡Œæš‚æ—¶ä¸ä¼ é€’å›è°ƒï¼Œå› ä¸ºåˆ‡åˆ†éå¸¸å¿«ï¼Œä¸»è¦è¿›åº¦åœ¨è½¬å½•
    )
    
    if not audio_chunks:
        yield "error", 0, "éŸ³é¢‘åˆ‡åˆ†å¤±è´¥ï¼Œç¨‹åºé€€å‡ºã€‚"
        return

    current_progress += 1
    yield "progress", current_progress / total_steps, f"è§†é¢‘åˆ‡åˆ†å®Œæˆï¼Œå¾—åˆ° {len(audio_chunks)} ä¸ªéŸ³é¢‘å—ã€‚"

    # --- æ­¥éª¤ 2: å¹¶è¡Œè½¬å½• ---
    yield "progress", current_progress / total_steps, f"æ­¥éª¤ 2/4: æ­£åœ¨å¹¶è¡Œè½¬å½• {len(audio_chunks)} ä¸ªéŸ³é¢‘å—..."
    
    all_transcripts = []
    num_transcribed = 0

    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_to_chunk = {executor.submit(transcribe_single_audio_chunk, chunk, openai_api_key): chunk for chunk in audio_chunks}
        
        for future in concurrent.futures.as_completed(future_to_chunk):
            result = future.result()
            if result:
                all_transcripts.append(result)
            num_transcribed += 1
            # äº§å‡ºè¯¦ç»†çš„å­è¿›åº¦
            yield "sub_progress", num_transcribed / len(audio_chunks), f"æ­£åœ¨è½¬å½•... ({num_transcribed}/{len(audio_chunks)})"

    if not all_transcripts:
        yield "error", 0, "æ‰€æœ‰éŸ³é¢‘å—éƒ½æœªèƒ½æˆåŠŸè½¬å½•ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–OpenAI APIå¯†é’¥ã€‚"
        return

    current_progress += 1
    yield "progress", current_progress / total_steps, "æ‰€æœ‰éŸ³é¢‘å—è½¬å½•å®Œæˆï¼"
    
    # --- æ­¥éª¤ 3: æ±‡æ€»ä¿å­˜ ---
    yield "progress", current_progress / total_steps, "æ­¥éª¤ 3/4: æ­£åœ¨æ±‡æ€»æ–‡å­—ç¨¿..."
    full_transcript = "\n\n".join(all_transcripts)
    try:
        with open(transcript_save_path, "w", encoding="utf-8") as f:
            f.write(full_transcript)
    except IOError as e:
        yield "error", 0, f"ä¿å­˜ä¸´æ—¶æ–‡å­—ç¨¿å¤±è´¥: {e}"
        return

    current_progress += 1
    yield "progress", current_progress / total_steps, "æ–‡å­—ç¨¿æ±‡æ€»å®Œæˆã€‚"

    # --- æ­¥éª¤ 4: Dify å¤„ç† ---
    yield "progress", current_progress / total_steps, "æ­¥éª¤ 4/4: æ­£åœ¨æäº¤ç»™ Dify å·¥ä½œæµ..."

    workflow_success = run_workflow(
        input_text=full_transcript,
        user="streamlit_user", # å¯ä»¥ç¡¬ç¼–ç æˆ–ä»ç•Œé¢è·å–
        dify_api_key=dify_api_key,
        input_variable_name="source_transcript", # ä»configè·å–æˆ–ç¡¬ç¼–ç 
        output_variable_name="final_output",
        local_save_path=final_notes_save_path
    )
    
    if not workflow_success:
        yield "error", 0, "Dify å·¥ä½œæµæ‰§è¡Œå¤±è´¥ã€‚"
        return

    current_progress += 1
    yield "progress", current_progress / total_steps, "å¤„ç†å®Œæˆï¼"
    yield "done", final_notes_save_path, "ğŸ‰ æ­å–œï¼æ™ºèƒ½ç¬”è®°å·²ç”Ÿæˆï¼"
