# main.py
import concurrent.futures
import time
import os
import shutil
from openai import AuthenticationError
from video_processor.splitter import split_media_to_audio_chunks_generator
from video_processor.transcriber import transcribe_single_audio_chunk, transcribe_local_with_choice
from dify_api import run_workflow_streaming

def main_process_generator(input_path: str, openai_api_key: str | None, dify_api_key: str, output_filename: str, query: str, transcription_provider: str, local_model_selection: str | None, output_chinese_format: str):
    output_dir = "output_chunks"
    final_notes_save_path = f"{output_filename}.md"
    intermediate_dir = "ä¸­é—´æ–‡ä»¶"
    os.makedirs(intermediate_dir, exist_ok=True)
    
    video_exts = {'.mp4', '.mov', '.mpeg', '.webm'}
    audio_exts = {'.mp3', '.m4a', '.wav', '.amr', '.mpga'}
    text_exts = {'.txt', '.md', '.mdx', '.markdown', '.pdf', '.html', '.xlsx', '.xls', '.doc', '.docx', '.csv', '.eml', '.msg', '.pptx', '.ppt', '.xml', '.epub'}

    file_ext = os.path.splitext(input_path)[1].lower()
    current_progress = 0
    full_transcript = ""

    def run_dify_and_yield_results():
        final_llm_output_chunks = []
        final_outputs = None

        dify_generator = run_workflow_streaming(
            input_text=full_transcript,
            query=query,
            user="streamlit_user",
            dify_api_key=dify_api_key
        )
        
        for event_type, data in dify_generator:
            if event_type == "text_chunk":
                final_llm_output_chunks.append(data)
                yield "llm_chunk", data
            
            elif event_type == "classification_result":
                category_map = {
                    "NOTES_STEM": "è¿™æ˜¯ä¸€ä¸ªç†å·¥ç§‘ (STEM) é¢†åŸŸçš„ç¬”è®°",
                    "NOTES_HASS": "è¿™æ˜¯ä¸€ä¸ªâ¼ˆæ–‡ç¤¾ç§‘ (HASS) é¢†åŸŸçš„ç¬”è®°",
                }
                friendly_text = category_map.get(data, f"æ— æ³•è¯†åˆ«ç¬”è®°é¢†åŸŸï¼Œå°†ä½¿ç”¨é»˜è®¤æ¨¡æ¿ã€‚è¯†åˆ«ç : {data}")
                yield "display_classification", friendly_text
                
            elif event_type == "error":
                user_friendly_error = f"**ç¬”è®°ç”Ÿæˆå¤±è´¥**\n\nçœ‹èµ·æ¥åœ¨ä¸ Dify æœåŠ¡é€šä¿¡æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¿™é€šå¸¸ä¸ API Key æˆ–ç½‘ç»œæœ‰å…³ã€‚\n\n**åŸå§‹é”™è¯¯ä¿¡æ¯:**\n`{data}`"
                yield "persistent_error", 0, user_friendly_error
                return

            elif event_type == "node_started":
                yield "progress_text", f"Dify èŠ‚ç‚¹ '{data}' å·²å¼€å§‹..."

            elif event_type == "workflow_finished":
                final_outputs = data
                break
        
        final_text_from_chunks = "".join(final_llm_output_chunks)
        final_output_value = final_outputs.get('final_output', '').strip() if final_outputs else ""

        if final_output_value == 'INJECTION_DETECTED':
            error_message = "**å®‰å…¨è­¦å‘Šï¼šæ£€æµ‹åˆ°æŒ‡ä»¤æ³¨å…¥æ”»å‡»**\n\næ‚¨çš„è¾“å…¥ä¸­å¯èƒ½åŒ…å«è¯•å›¾æ“æ§ç³»ç»Ÿè¡Œä¸ºçš„æŒ‡ä»¤ã€‚ä¸ºå®‰å…¨èµ·è§ï¼Œå¤„ç†å·²ç»ˆæ­¢ã€‚"
            yield "persistent_error", 0, error_message
            return

        if final_output_value == 'SENSITIVE_CONTENT_DETECTED':
            error_message = "**å†…å®¹è­¦å‘Šï¼šæ£€æµ‹åˆ°ä¸å½“æ•æ„Ÿå†…å®¹**\n\næ‚¨çš„è¾“å…¥ä¸­å¯èƒ½åŒ…å«ä¸é€‚å®œçš„è¯æ±‡ã€‚ä¸ºéµå®ˆç¤¾åŒºå‡†åˆ™ï¼Œå¤„ç†å·²ç»ˆæ­¢ã€‚"
            yield "persistent_error", 0, error_message
            return
        
        if final_output_value == query:
            error_message = ""
            if query == "Notes":
                error_message = "**ç¬”è®°ç”Ÿæˆå¤±è´¥**\n\næ— æ³•è‡ªåŠ¨è¯†åˆ«ç¬”è®°çš„é¢†åŸŸ (ä¾‹å¦‚ç†å·¥ç§‘/äººæ–‡ç¤¾ç§‘)ã€‚å·¥ä½œæµå·²ç»ˆæ­¢ï¼Œå› ä¸ºå®ƒæ— æ³•é€‰æ‹©åˆé€‚çš„ç¬”è®°æ¨¡æ¿ã€‚"
            else:
                error_message = f"**æ— æ•ˆçš„æ“ä½œç±»å‹**\n\nè¯·æ±‚çš„æ“ä½œ '{query}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„é€‰é¡¹ ('Notes', 'Q&A', 'Quiz')ã€‚å·¥ä½œæµå·²ç»ˆæ­¢ã€‚"
            yield "persistent_error", 0, error_message
            return
        
        final_text = final_text_from_chunks
        
        if "</think>" in final_text:
            final_text = final_text.split("</think>")[-1].strip()

        if not final_text:
            yield "persistent_error", 0, "**ç¬”è®°ç”Ÿæˆå¤±è´¥**\n\nDify å·¥ä½œæµåœ¨å¤šæ¬¡å°è¯•åï¼Œæœªè¿”å›ä»»ä½•æœ‰æ•ˆå†…å®¹ã€‚è¯·æ£€æŸ¥æ‚¨çš„ Dify å·¥ä½œæµé…ç½®ä»¥åŠè¾“å…¥æ–‡æœ¬æ˜¯å¦è¿‡é•¿æˆ–æ ¼å¼å¼‚å¸¸ã€‚"
            return

        try:
            with open(final_notes_save_path, 'w', encoding='utf-8') as f:
                f.write(final_text)
            yield "save_path", final_notes_save_path
        except IOError as e:
            user_friendly_error = f"**ä¿å­˜æœ€ç»ˆç¬”è®°æ–‡ä»¶å¤±è´¥**\n\næ— æ³•å°†ç”Ÿæˆçš„ç¬”è®°å†™å…¥æœ¬åœ°æ–‡ä»¶ã€‚\n\n**å¯èƒ½åŸå› :**\n- ç¨‹åºæ²¡æœ‰åœ¨å½“å‰ç›®å½•åˆ›å»ºæ–‡ä»¶çš„æƒé™ã€‚\n- ç£ç›˜ç©ºé—´ä¸è¶³ã€‚\n\n**åŸå§‹é”™è¯¯ä¿¡æ¯:**\n`{e}`"
            yield "persistent_error", 0, user_friendly_error
            return

    if file_ext in text_exts:
        total_steps = 2
        yield "progress", 0 / total_steps, "æ­¥éª¤ 1/2: æ­£åœ¨è¯»å–æ–‡æœ¬æ–‡æ¡£..."
        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                full_transcript = f.read()
        except Exception as e:
            user_friendly_error = f"**è¯»å–æ–‡ä»¶å¤±è´¥**\n\næ— æ³•è¯»å–æ‚¨ä¸Šä¼ çš„æ–‡æœ¬æ–‡æ¡£ '{os.path.basename(input_path)}'ã€‚\n\n**å¯èƒ½åŸå› :**\n- æ–‡ä»¶å·²æŸåæˆ–ç¼–ç æ ¼å¼ä¸æ˜¯ UTF-8ã€‚\n- ç¨‹åºæ²¡æœ‰è¯»å–è¯¥æ–‡ä»¶çš„æƒé™ã€‚\n\n**åŸå§‹é”™è¯¯ä¿¡æ¯:**\n`{e}`"
            yield "persistent_error", 0, user_friendly_error
            return
        
        current_progress += 1
        yield "progress", current_progress / total_steps, "æ­¥éª¤ 2/2: æ­£åœ¨æäº¤ç»™ Dify å·¥ä½œæµ (æµå¼ä¼ è¾“)..."
        
        final_path = None
        dify_gen = run_dify_and_yield_results()
        for event_type, value, *rest in dify_gen:
            if event_type == "persistent_error":
                yield event_type, value, rest[0]
                return
            elif event_type == "display_classification":
                yield event_type, value
            elif event_type == "llm_chunk":
                yield event_type, value
            elif event_type == "progress_text":
                yield "progress", current_progress / total_steps, value
            elif event_type == "save_path":
                final_path = value
                
        if final_path:
            current_progress += 1
            yield "progress", current_progress / total_steps, "å¤„ç†å®Œæˆï¼"
            yield "done", final_path, "ğŸ‰ æ­å–œï¼æ™ºèƒ½ç¬”è®°å·²ç”Ÿæˆï¼"
        return

    elif file_ext in video_exts or file_ext in audio_exts:
        is_video = file_ext in video_exts
        total_steps = 4 if is_video else 3
        
        step_name = "è§†é¢‘" if is_video else "éŸ³é¢‘"
        yield "progress", current_progress / total_steps, f"æ­¥éª¤ {current_progress + 1}/{total_steps}: æ­£åœ¨åˆ‡åˆ†{step_name}ä¸ºéŸ³é¢‘å—..."
        
        splitter_generator = split_media_to_audio_chunks_generator(input_path, output_dir, 600)
        audio_chunks = []
        
        for event_type, val1, *val2 in splitter_generator:
            if event_type == 'progress':
                completed, total = val1, val2[0]
                yield "sub_progress", completed / total, f"æ­£åœ¨åˆ‡åˆ†... ({completed}/{total})"
            elif event_type == 'result':
                audio_chunks = val1
            elif event_type == 'error':
                user_friendly_error = f"**åª’ä½“æ–‡ä»¶åˆ‡åˆ†å¤±è´¥**\n\næ— æ³•å¤„ç†æ‚¨ä¸Šä¼ çš„åª’ä½“æ–‡ä»¶ã€‚è¿™é€šå¸¸ä¸ **FFmpeg** é…ç½®æˆ–æ–‡ä»¶æœ¬èº«æœ‰å…³ã€‚\n\n**è¯·æ£€æŸ¥:**\n1. **FFmpeg æ˜¯å¦å·²æ­£ç¡®å®‰è£…**: ç¡®ä¿ FFmpeg å·²å®‰è£…å¹¶åœ¨ç³»ç»Ÿçš„ç¯å¢ƒå˜é‡ `PATH` ä¸­ã€‚\n2. **æ–‡ä»¶æ˜¯å¦å®Œå¥½**: ç¡®è®¤æ‚¨çš„æ–‡ä»¶ `{os.path.basename(input_path)}` æ²¡æœ‰æŸåä¸”æ ¼å¼å—æ”¯æŒã€‚\n\n**åŸå§‹é”™è¯¯ä¿¡æ¯:**\n`{val1}`"
                yield "persistent_error", 0, user_friendly_error
                return
        
        if not audio_chunks:
            yield "persistent_error", 0, f"**{step_name}åˆ‡åˆ†å¤±è´¥**\n\næœªèƒ½ä»æ‚¨çš„æ–‡ä»¶ä¸­æå–å‡ºä»»ä½•éŸ³é¢‘å—ã€‚è¯·ç¡®ä¿æ–‡ä»¶æ—¶é•¿ä¸ä¸ºé›¶ï¼Œä¸”å·²æ­£ç¡®å®‰è£… FFmpegã€‚"
            return
        
        yield "sub_progress", 1.0, f"âœ… {step_name}åˆ‡åˆ†å…¨éƒ¨å®Œæˆï¼"
        current_progress += 1
        yield "progress", current_progress / total_steps, f"âœ… {step_name}åˆ‡åˆ†å®Œæˆï¼Œå‡†å¤‡å¼€å§‹è½¬å½•..."

        yield "progress", current_progress / total_steps, f"æ­¥éª¤ {current_progress + 1}/{total_steps}: æ­£åœ¨å¹¶è¡Œè½¬å½• {len(audio_chunks)} ä¸ªéŸ³é¢‘å—..."
        all_transcripts = [None] * len(audio_chunks)
        num_transcribed = 0

        if transcription_provider == 'openai_api':
            transcribe_func = transcribe_single_audio_chunk
            max_workers = 10
            tasks_args_list = [(chunk, openai_api_key, output_chinese_format) for chunk in audio_chunks]
        else:
            transcribe_func = transcribe_local_with_choice
            max_workers = 1
            tasks_args_list = [(chunk, local_model_selection, output_chinese_format) for chunk in audio_chunks]

        try:
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_index = {
                    executor.submit(transcribe_func, *args): i
                    for i, args in enumerate(tasks_args_list)
                }
                for future in concurrent.futures.as_completed(future_to_index):
                    index = future_to_index[future]
                    result = future.result() 
                    if result is not None:
                        all_transcripts[index] = result
                    else:
                        raise Exception(f"è½¬å½•ä»»åŠ¡æœªè¿”å›æœ‰æ•ˆæ–‡æœ¬ (å—ç´¢å¼•: {index})ã€‚")
                    
                    num_transcribed += 1
                    yield "sub_progress", num_transcribed / len(audio_chunks), f"æ­£åœ¨è½¬å½•... ({num_transcribed}/{len(audio_chunks)})"

        except AuthenticationError as e:
             user_friendly_error = f"**OpenAI API è®¤è¯å¤±è´¥**\n\næ‚¨çš„ OpenAI API Key æ— æ•ˆã€‚è¯·åœ¨å·¦ä¾§è¾¹æ é‡æ–°è¾“å…¥æ­£ç¡®çš„å¯†é’¥ã€‚\n\n**å¸¸è§åŸå› :**\n- å¯†é’¥æ‹¼å†™é”™è¯¯ã€‚\n- å¯†é’¥å·²è¿‡æœŸæˆ–è¢«ç¦ç”¨ã€‚\n- è´¦æˆ·ä½™é¢ä¸è¶³ã€‚\n\n**åŸå§‹é”™è¯¯ä¿¡æ¯:**\n`{e}`"
             yield "persistent_error", 0, user_friendly_error
             return
        except Exception as e:
            mode_text = "OpenAI Whisper æœåŠ¡" if transcription_provider == 'openai_api' else f"æœ¬åœ°æ¨¡å‹ ({local_model_selection})"
            user_friendly_error = f"**éŸ³é¢‘è½¬å½•å¤±è´¥**\n\nåœ¨ä½¿ç”¨ {mode_text} è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—æ—¶å‘ç”Ÿæ— æ³•æ¢å¤çš„é”™è¯¯ã€‚\n\n**å¯èƒ½åŸå› :**\n1. (APIæ¨¡å¼) **OpenAI æœåŠ¡ä¸­æ–­**\n2. (APIæ¨¡å¼) **ç½‘ç»œè¿æ¥é—®é¢˜**\n3. (æœ¬åœ°æ¨¡å¼) **æ¨¡å‹åº“æˆ–æ¨¡å‹æ–‡ä»¶é—®é¢˜**\n4. **éŸ³é¢‘æ•°æ®å·²æŸå**\n\n**åŸå§‹é”™è¯¯ä¿¡æ¯:**\n`{e}`"
            yield "persistent_error", 0, user_friendly_error
            return
        
        if any(t is None for t in all_transcripts):
            yield "persistent_error", 0, "**éŸ³é¢‘è½¬å½•ä¸å®Œæ•´**\n\néƒ¨åˆ†éŸ³é¢‘å—åœ¨å¤šæ¬¡å°è¯•åä»ç„¶è½¬å½•å¤±è´¥ã€‚ä¸ºç¡®ä¿ç¬”è®°çš„å®Œæ•´æ€§ï¼Œå¤„ç†å·²ä¸­æ­¢ã€‚"
            return

        yield "sub_progress", 1.0, "âœ… éŸ³é¢‘è½¬å½•å…¨éƒ¨å®Œæˆï¼"
        current_progress += 1
        yield "progress", current_progress / total_steps, "æ‰€æœ‰éŸ³é¢‘å—è½¬å½•å®Œæˆï¼"
        
        step_name_after_transcription = "æ±‡æ€»æ–‡å­—ç¨¿å¹¶ä¿å­˜..." if is_video else "ä¿å­˜æ–‡å­—ç¨¿..."
        yield "progress", current_progress / total_steps, f"æ­¥éª¤ {current_progress + 1}/{total_steps}: æ­£åœ¨{step_name_after_transcription}"
        
        full_transcript = "\n\n".join(filter(None, all_transcripts))
        
        transcript_save_path = os.path.join(intermediate_dir, "source_transcript.txt")
        try:
            with open(transcript_save_path, 'w', encoding='utf-8') as f:
                f.write(full_transcript)
        except IOError as e:
            yield "error", 0, f"æ— æ³•ä¿å­˜æ–‡å­—ç¨¿æ–‡ä»¶: {e}"

        current_progress += 1
        yield "progress", current_progress / total_steps, "æ–‡å­—ç¨¿ä¿å­˜å®Œæˆã€‚"
            
        yield "progress", current_progress / total_steps, f"æ­¥éª¤ {current_progress + 1}/{total_steps}: æ­£åœ¨æäº¤ç»™ Dify å·¥ä½œæµ (æµå¼ä¼ è¾“)..."

        final_path = None
        dify_gen = run_dify_and_yield_results()
        for event_type, value, *rest in dify_gen:
            if event_type == "persistent_error":
                yield event_type, value, rest[0]
                return
            elif event_type == "display_classification":
                yield event_type, value
            elif event_type == "llm_chunk":
                yield event_type, value
            elif event_type == "progress_text":
                 yield "progress", current_progress / total_steps, value
            elif event_type == "save_path":
                final_path = value
        
        if final_path:
            current_progress += 1
            yield "progress", current_progress / total_steps, "å¤„ç†å®Œæˆï¼"
            yield "done", final_path, "ğŸ‰ æ­å–œï¼æ™ºèƒ½ç¬”è®°å·²ç”Ÿæˆï¼"
        return
        
    else:
        user_friendly_error = f"**ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹**\n\næ‚¨ä¸Šä¼ çš„æ–‡ä»¶ç±»å‹ (`{file_ext}`) å½“å‰ä¸å—æ”¯æŒã€‚è¯·å‚ç…§ä¸Šä¼ æ¡†ä¸‹çš„æç¤ºï¼Œä¸Šä¼ æŒ‡å®šæ ¼å¼çš„è§†é¢‘ã€éŸ³é¢‘æˆ–æ–‡æœ¬æ–‡æ¡£ã€‚"
        yield "error", 0, user_friendly_error
        return