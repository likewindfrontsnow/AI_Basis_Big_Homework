# app.py
import streamlit as st
import os
from main import main_process_generator
from config import DIFY_API_KEY 

st.set_page_config(page_title="æ™ºèƒ½ç¬”è®° Agent", layout="wide")
st.title("ğŸ‘¨â€ğŸ’» æ™ºèƒ½å†…å®¹ç”Ÿæˆ Agent")
st.markdown("ä¸Šä¼ æ‚¨çš„è§†é¢‘ã€éŸ³é¢‘æˆ–æ–‡æœ¬æ–‡æ¡£ï¼Œå³å¯è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–ç¬”è®°ã€Q&A æˆ–æµ‹éªŒã€‚")

st.info(
    "ğŸ’¡ **æç¤º**: å¤„ç†æ–‡æœ¬æ–‡æ¡£å®Œå…¨å…è´¹ã€‚å¤„ç†è§†é¢‘æˆ–éŸ³é¢‘æ—¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©é€Ÿåº¦å¿«ä½†ä»˜è´¹çš„ OpenAI APIï¼Œ"
    "æˆ–é€‰æ‹©å®Œå…¨å…è´¹ä½†é€Ÿåº¦è¾ƒæ…¢çš„æœ¬åœ°å¤„ç†æ¨¡å¼ã€‚"
)

with st.sidebar:
    st.header("âš™ï¸ å‚æ•°é…ç½®")
    
    transcription_provider = st.selectbox(
        "è¯·é€‰æ‹©è¯­éŸ³è½¬æ–‡å­—æ–¹å¼:",
        ("OpenAI API (é€Ÿåº¦å¿«)", "æœ¬åœ°å¤„ç† (å…è´¹ä½†è¾ƒæ…¢)"),
        index=0,
        help=(
            "**OpenAI API**: é€Ÿåº¦å¿«ï¼Œç»“æœç¨³å®šï¼Œä½†éœ€è¦æ‚¨è‡ªå·±çš„ API Key ä¸”ä¼šäº§ç”Ÿè´¹ç”¨ã€‚"
            "**æœ¬åœ°å¤„ç†**: å®Œå…¨å…è´¹ï¼Œä½†é€Ÿåº¦æ˜¾è‘—æ…¢äºAPIï¼Œå°¤å…¶æ˜¯åœ¨æ²¡æœ‰GPUçš„ç”µè„‘ä¸Šã€‚é¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶ã€‚"
        )
    )
    provider_key = "local" if transcription_provider == "æœ¬åœ°å¤„ç† (å…è´¹ä½†è¾ƒæ…¢)" else "openai_api"

    local_model_selection = None
    if provider_key == "local":
        # å®šä¹‰æ¨¡å‹é€‰é¡¹åŠå…¶è¯´æ˜
        model_options = {
            # æ ¼å¼: "ç”¨æˆ·çœ‹åˆ°çš„åç§°": ("å†…éƒ¨æ ‡è¯†ç¬¦", "å¸®åŠ©è¯´æ˜")
            "Faster-Whisper (Large-v3, æ¨è)": (
                "faster-whisper-large-v3", 
                "é€Ÿåº¦ä¸è´¨é‡çš„æœ€ä½³å¹³è¡¡ã€‚é€šè¿‡ä¼˜åŒ–å¼•æ“ï¼Œç”¨æ¥è¿‘ä¸­ç­‰æ¨¡å‹çš„é€Ÿåº¦å®ç°æœ€é«˜è´¨é‡çš„è½¬å½•ã€‚"
            ),
            "Whisper - Large-v3 (å®˜æ–¹)": (
                "whisper-large-v3", 
                "å®˜æ–¹å®ç°ï¼Œæä¾›æœ€é«˜çš„å‡†ç¡®åº¦ï¼Œä½†åœ¨æ²¡æœ‰é¡¶çº§GPUçš„æƒ…å†µä¸‹é€Ÿåº¦ææ…¢ã€‚"
            ),
            "Whisper - Medium (å®˜æ–¹)": (
                "whisper-medium",
                "å®˜æ–¹å®ç°ï¼Œå‡†ç¡®åº¦è¾ƒå¥½ï¼Œé€Ÿåº¦æ…¢äº a Faster-Whisperï¼Œé€‚åˆä¸­é«˜ç«¯GPUã€‚"
            ),
            "Whisper - Base (å®˜æ–¹)": (
                "whisper-base",
                "å®˜æ–¹å®ç°ï¼Œé€Ÿåº¦æœ€å¿«ï¼Œå ç”¨èµ„æºæœ€å°‘ï¼Œä½†å‡†ç¡®åº¦ä¸ºåŸºç¡€æ°´å¹³ï¼Œé€‚åˆå¿«é€Ÿé¢„è§ˆæˆ–æ— GPUç¯å¢ƒã€‚"
            )
        }
        
        selected_model_name = st.selectbox(
            "è¯·é€‰æ‹©æœ¬åœ°æ¨¡å‹:",
            options=model_options.keys(),
            index=0, # é»˜è®¤é€‰ä¸­ç¬¬ä¸€ä¸ª "Faster-Whisper"
            help="ä¸åŒæ¨¡å‹åœ¨é€Ÿåº¦ã€å‡†ç¡®åº¦å’Œèµ„æºå ç”¨ä¸Šæœ‰æ‰€ä¸åŒã€‚é¦–æ¬¡ä½¿ç”¨ä¼šä¸‹è½½æ‰€é€‰æ¨¡å‹ã€‚"
        )
        local_model_selection, help_text = model_options[selected_model_name]
        st.info(help_text) # æ˜¾ç¤ºå½“å‰æ‰€é€‰æ¨¡å‹çš„è¯¦ç»†è¯´æ˜

    openai_api_key_input = st.text_input(
        "è¯·è¾“å…¥æ‚¨çš„ OpenAI API Key", 
        type="password", 
        help="æ‚¨çš„å¯†é’¥å°†ä»…ç”¨äºè§†é¢‘/éŸ³é¢‘çš„è¯­éŸ³è½¬å½•ï¼Œä¸ä¼šè¢«ä¿å­˜ã€‚",
        disabled=(provider_key == "local")
    )
    
    openai_api_key = openai_api_key_input if provider_key == "openai_api" else None

    output_filename = st.text_input("è¯·è¾“å…¥å¸Œæœ›çš„ç¬”è®°æ–‡ä»¶å (æ— éœ€åç¼€)", value="æˆ‘çš„å­¦ä¹ ç¬”è®°")

    query_option = st.selectbox(
        "è¯·é€‰æ‹©ç”Ÿæˆå†…å®¹ç±»å‹:",
        ("Notes", "Q&A", "Quiz"),
        index=0,
        help="é€‰æ‹© 'Notes' ç”Ÿæˆç»“æ„åŒ–ç¬”è®°, 'Q&A' ç”Ÿæˆé—®ç­”å¯¹, 'Quiz' ç”Ÿæˆæµ‹éªŒé¢˜ã€‚"
    )

    st.markdown("---")
    keep_temp_files = st.checkbox(
        "ä¿ç•™ä¸­é—´æ–‡ä»¶", 
        value=False, 
        help="å‹¾é€‰åå°†ä¿ç•™ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶å’Œè¯­éŸ³è½¬æ–‡å­—ç”Ÿæˆçš„ `source_transcript.txt`ã€‚"
    )

    st.info("è¯·åœ¨ä¸Šæ–¹é…ç½®å¥½å‚æ•°åï¼Œä¸Šä¼ æ–‡ä»¶å¼€å§‹å¤„ç†ã€‚")

video_exts = {'mp4', 'mov','mpeg','webm'}
audio_exts = {'mp3','m4a','wav','amr','mpga'}
doc_exts = {'txt','md','mdx','markdown','pdf','html','xlsx','xls','doc','docx','csv','eml','msg','pptx','ppt','xml','epub'}
all_exts = list(video_exts | audio_exts | doc_exts)

with st.expander("æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"):
    st.markdown(f"""
    - **è§†é¢‘æ–‡ä»¶**: `{', '.join(sorted(list(video_exts)))}`
    - **éŸ³é¢‘æ–‡ä»¶**: `{', '.join(sorted(list(audio_exts)))}`
    - **æ–‡æ¡£æ–‡ä»¶**: `{', '.join(sorted(list(doc_exts)))}`
    """)

uploaded_file = st.file_uploader(
    "ä¸Šä¼ è§†é¢‘ã€éŸ³é¢‘æˆ–æ–‡æ¡£", 
    type=all_exts
)

if uploaded_file is not None:
    if st.button("å¼€å§‹ç”Ÿæˆ", use_container_width=True, type="primary"):
        
        file_ext = os.path.splitext(uploaded_file.name)[1].lower().replace('.', '')
        is_media_file = file_ext in video_exts or file_ext in audio_exts

        if is_media_file and provider_key == "openai_api" and not openai_api_key:
            st.error("âŒ æ‚¨é€‰æ‹©äº† OpenAI API æ¨¡å¼ï¼Œè¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ API Keyã€‚")
        else:
            st.markdown("---")
            st.subheader("å¤„ç†è¿›åº¦")
            
            main_progress_bar = st.progress(0)
            main_progress_text = st.empty()
            sub_progress_bar = st.progress(0)
            sub_progress_text = st.empty()

            st.markdown("---")

            processing_headers = {
                "Notes": "æ­£åœ¨ç”Ÿæˆç¬”è®° (å®æ—¶è¾“å‡ºä¸­...)",
                "Q&A": "æ­£åœ¨è¿›è¡Œ Q&A (å®æ—¶è¾“å‡ºä¸­...)",
                "Quiz": "æ­£åœ¨ç”Ÿæˆæµ‹éªŒ (å®æ—¶è¾“å‡ºä¸­...)"
            }
            st.subheader(processing_headers.get(query_option, "æ­£åœ¨å¤„ç†..."))
            st.info(f"å½“å‰ç”Ÿæˆæ¨¡å¼: **{query_option}**")

            if provider_key == "local":
                 st.info(f"å½“å‰æœ¬åœ°æ¨¡å‹: **{local_model_selection}**")
            
            classification_display = st.empty()
            llm_output_container = st.empty()
            full_llm_response = ""
            
            final_result_path = None
            processing_has_failed = False

            temp_dir = "temp_uploads"
            if not os.path.exists(temp_dir):
                os.makedirs(temp_dir)
            temp_file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(temp_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            generator = main_process_generator(
                input_path=temp_file_path, 
                openai_api_key=openai_api_key, 
                dify_api_key=DIFY_API_KEY, 
                output_filename=output_filename, 
                query=query_option,
                transcription_provider=provider_key,
                local_model_selection=local_model_selection # æ–°å¢å‚æ•°
            )

            for event_type, value, *rest in generator:
                text = rest[0] if rest else ""

                if event_type == "progress":
                    main_progress_bar.progress(float(value))
                    main_progress_text.info(text)
                elif event_type == "sub_progress":
                    sub_progress_bar.progress(float(value))
                    sub_progress_text.text(text)
                
                elif event_type == "display_classification":
                    classification_display.success(f"âœ… **ç¬”è®°åˆ†ç±»**: {value}")

                elif event_type == "llm_chunk":
                    full_llm_response += value
                    llm_output_container.markdown(full_llm_response + " â–Œ")
                
                elif event_type == "persistent_error":
                    st.error(f"å¤„ç†å¤±è´¥: {text}")
                    main_progress_text.error("ä¸€ä¸ªå…³é”®æ­¥éª¤åœ¨å¤šæ¬¡é‡è¯•åä»ç„¶å¤±è´¥ï¼Œå·²åœæ­¢å¤„ç†ã€‚")
                    llm_output_container.error(f"**é”™è¯¯è¯¦æƒ…:**\n\n{text}")
                    if st.button("ğŸ”„ é‡æ–°å¼€å§‹"):
                        st.experimental_rerun()
                    processing_has_failed = True
                    break
                
                elif event_type == "error":
                    st.error(text)
                    llm_output_container.error(text)
                    processing_has_failed = True
                    break

                elif event_type == "done":
                    main_progress_bar.progress(1.0)
                    sub_progress_bar.empty()
                    sub_progress_text.empty()
                    llm_output_container.markdown(full_llm_response)
                    st.success(text)
                    final_result_path = value
            
            if final_result_path and os.path.exists(final_result_path) and not processing_has_failed:
                st.download_button(
                    label=f"ä¸‹è½½ç»“æœ ({os.path.basename(final_result_path)})",
                    data=full_llm_response,
                    file_name=os.path.basename(final_result_path),
                    mime="text/markdown",
                    use_container_width=True
                )
            
            if not keep_temp_files:
                try:
                    if os.path.exists(temp_file_path):
                        os.remove(temp_file_path)
                except OSError as e:
                    st.warning(f"æ— æ³•è‡ªåŠ¨åˆ é™¤ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶ '{temp_file_path}': {e}")

                transcript_path = "source_transcript.txt"
                try:
                    if os.path.exists(transcript_path):
                        os.remove(transcript_path)
                except OSError as e:
                    st.warning(f"æ— æ³•è‡ªåŠ¨åˆ é™¤æ–‡å­—ç¨¿æ–‡ä»¶ '{transcript_path}': {e}")
            else:
                st.info("å·²æ ¹æ®æ‚¨çš„è®¾ç½®ï¼Œä¿ç•™äº†ä¸­é—´æ–‡ä»¶ã€‚")