# app.py
import streamlit as st
import os
import shutil
from main import main_process_generator
from config import DIFY_API_KEY 

st.set_page_config(page_title="æ™ºèƒ½ç¬”è®° Agent", layout="wide")
st.title("ğŸ‘¨â€ğŸ’» æ™ºèƒ½å†…å®¹ç”Ÿæˆ Agent")
st.markdown("ä¸Šä¼ æ‚¨çš„è§†é¢‘ã€éŸ³é¢‘æˆ–æ–‡æœ¬æ–‡æ¡£ï¼Œå³å¯è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–ç¬”è®°ã€Q&A æˆ–æµ‹éªŒã€‚")

with st.sidebar:
    st.header("âš™ï¸ å‚æ•°é…ç½®")
    
    with st.expander("æœ¬åœ°æ¨¡å‹åŠ è½½è¯´æ˜", expanded=False):
        st.info(
            """
            - **é¦–æ¬¡åŠ è½½æ…¢**: å½“æ‚¨ç¬¬ä¸€æ¬¡é€‰æ‹©æŸä¸ªæœ¬åœ°æ¨¡å‹æ—¶ï¼Œç¨‹åºéœ€è¦å°†å…¶ä»ç¡¬ç›˜åŠ è½½åˆ°å†…å­˜/æ˜¾å­˜ï¼Œæ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚
            - **åç»­ä½¿ç”¨å¿«**: ä¸€æ—¦åŠ è½½æˆåŠŸï¼Œæ¨¡å‹ä¼šé©»ç•™åœ¨å†…å­˜ä¸­ã€‚åœ¨æœ¬æ¬¡ä¼šè¯ä¸­å†æ¬¡ä½¿ç”¨è¯¥æ¨¡å‹ï¼Œå°†æ— éœ€ç­‰å¾…åŠ è½½ã€‚
            - **æ¨¡å‹å­˜æ”¾ä½ç½®**: æ‰€æœ‰æœ¬åœ°æ¨¡å‹éƒ½åº”æ”¾ç½®åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ â€œå¤§æ¨¡å‹â€ æ–‡ä»¶å¤¹ä¸­ï¼Œç¨‹åºä¼šè‡ªåŠ¨ä»æ­¤è·¯å¾„åŠ è½½ã€‚
            """
        )

    transcription_provider = st.selectbox(
        "è¯·é€‰æ‹©è¯­éŸ³è½¬æ–‡å­—æ–¹å¼:",
        ("OpenAI API (é€Ÿåº¦å¿«)", "æœ¬åœ°å¤„ç† (å…è´¹ä½†è¾ƒæ…¢)"),
        index=0,
        help=(
            "**OpenAI API**: é€Ÿåº¦å¿«ï¼Œç»“æœç¨³å®šï¼Œä½†éœ€è¦æ‚¨è‡ªå·±çš„ API Key ä¸”ä¼šäº§ç”Ÿè´¹ç”¨ã€‚"
            "**æœ¬åœ°å¤„ç†**: å®Œå…¨å…è´¹ï¼Œä½†é€Ÿåº¦æ˜¾è‘—æ…¢äºAPIã€‚è¯·ç¡®ä¿å·²æŒ‰è¯´æ˜é…ç½®å¥½â€œå¤§æ¨¡å‹â€æ–‡ä»¶å¤¹ã€‚"
        )
    )
    provider_key = "local" if transcription_provider == "æœ¬åœ°å¤„ç† (å…è´¹ä½†è¾ƒæ…¢)" else "openai_api"

    local_model_selection = None
    if provider_key == "local":
        model_options = {
            "Faster-Whisper (Large-v3, æ¨è)": ("faster-whisper-large-v3", "é€Ÿåº¦ä¸è´¨é‡çš„æœ€ä½³å¹³è¡¡ã€‚"),
            "Whisper - Large-v3 (å®˜æ–¹)": ("whisper-large-v3", "å®˜æ–¹å®ç°ï¼Œæä¾›æœ€é«˜çš„å‡†ç¡®åº¦ï¼Œä½†åœ¨æ²¡æœ‰é¡¶çº§GPUçš„æƒ…å†µä¸‹é€Ÿåº¦ææ…¢ã€‚"),
            "Whisper - Medium (å®˜æ–¹)": ("whisper-medium", "å®˜æ–¹å®ç°ï¼Œå‡†ç¡®åº¦è¾ƒå¥½ï¼Œé€Ÿåº¦æ…¢äº Faster-Whisperã€‚"),
            "Whisper - Base (å®˜æ–¹)": ("whisper-base", "å®˜æ–¹å®ç°ï¼Œé€Ÿåº¦æœ€å¿«ï¼Œå ç”¨èµ„æºæœ€å°‘ï¼Œä½†å‡†ç¡®åº¦ä¸ºåŸºç¡€æ°´å¹³ã€‚")
        }
        selected_model_name = st.selectbox(
            "è¯·é€‰æ‹©æœ¬åœ°æ¨¡å‹:", options=model_options.keys(), index=0,
            help="ä¸åŒæ¨¡å‹åœ¨é€Ÿåº¦ã€å‡†ç¡®åº¦å’Œèµ„æºå ç”¨ä¸Šæœ‰æ‰€ä¸åŒã€‚"
        )
        local_model_selection, help_text = model_options[selected_model_name]
        st.info(help_text)

    st.markdown("---")
    output_chinese_format = st.radio(
        "é€‰æ‹©ä¸­æ–‡è¾“å‡ºæ ¼å¼:",
        ("ç®€ä½“ä¸­æ–‡", "ç¹é«”ä¸­æ–‡"),
        index=0,
        horizontal=True,
        help="æ­¤é€‰é¡¹ä»…åœ¨è½¬å½•å†…å®¹è¢«è¯†åˆ«ä¸ºä¸­æ–‡æ—¶ç”Ÿæ•ˆã€‚"
    )
    format_key = "simplified" if output_chinese_format == "ç®€ä½“ä¸­æ–‡" else "traditional"

    openai_api_key_input = st.text_input(
        "è¯·è¾“å…¥æ‚¨çš„ OpenAI API Key", type="password", help="æ‚¨çš„å¯†é’¥å°†ä»…ç”¨äºè§†é¢‘/éŸ³é¢‘çš„è¯­éŸ³è½¬å½•ï¼Œä¸ä¼šè¢«ä¿å­˜ã€‚",
        disabled=(provider_key == "local")
    )
    openai_api_key = openai_api_key_input if provider_key == "openai_api" else None
    output_filename = st.text_input("è¯·è¾“å…¥å¸Œæœ›çš„ç¬”è®°æ–‡ä»¶å (æ— éœ€åç¼€)", value="æˆ‘çš„å­¦ä¹ ç¬”è®°")
    query_option = st.selectbox(
        "è¯·é€‰æ‹©ç”Ÿæˆå†…å®¹ç±»å‹:", ("Notes", "Q&A", "Quiz"), index=0,
        help="é€‰æ‹© 'Notes' ç”Ÿæˆç»“æ„åŒ–ç¬”è®°, 'Q&A' ç”Ÿæˆé—®ç­”å¯¹, 'Quiz' ç”Ÿæˆæµ‹éªŒé¢˜ã€‚"
    )
    st.markdown("---")
    keep_temp_files = st.checkbox(
        "ä¿ç•™ä¸­é—´æ–‡ä»¶", value=False, help="å‹¾é€‰åå°†ä¿ç•™ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶ã€éŸ³é¢‘å—å’Œè½¬å†™ç¨¿ã€‚"
    )
    st.info("è¯·åœ¨ä¸Šæ–¹é…ç½®å¥½å‚æ•°åï¼Œä¸Šä¼ æ–‡ä»¶å¼€å§‹å¤„ç†ã€‚")

video_exts = {'mp4', 'mov','mpeg','webm'}
audio_exts = {'mp3','m4a','wav','amr','mpga'}
doc_exts = {'txt','md','mdx','markdown','pdf','html','xlsx','xls','doc','docx','csv','eml','msg','pptx','ppt','xml','epub'}
all_exts = list(video_exts | audio_exts | doc_exts)

with st.expander("æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"):
    st.markdown(f"""
    - **è§†é¢‘æ–‡ä»¶**: `{', '.join(sorted(list(video_exts)))}`
    - **éŸ³é¢‘æ–‡ä»¶**: `{', '.join(sorted(list(audio_exts)))}`
    - **æ–‡æ¡£æ–‡ä»¶**: `{', '.join(sorted(list(doc_exts)))}`
    """)

uploaded_file = st.file_uploader("ä¸Šä¼ è§†é¢‘ã€éŸ³é¢‘æˆ–æ–‡æ¡£", type=all_exts)

if uploaded_file is not None:
    if st.button("å¼€å§‹ç”Ÿæˆ", use_container_width=True, type="primary"):
        file_ext = os.path.splitext(uploaded_file.name)[1].lower().replace('.', '')
        is_media_file = file_ext in video_exts or file_ext in audio_exts
        if is_media_file and provider_key == "openai_api" and not openai_api_key:
            st.error("âŒ æ‚¨é€‰æ‹©äº† OpenAI API æ¨¡å¼ï¼Œè¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ API Keyã€‚")
        else:
            st.markdown("---")
            st.subheader("å¤„ç†è¿›åº¦")
            main_progress_bar = st.progress(0)
            main_progress_text = st.empty()
            sub_progress_bar = st.progress(0)
            sub_progress_text = st.empty()
            st.markdown("---")
            processing_headers = {
                "Notes": "æ­£åœ¨ç”Ÿæˆç¬”è®° (å®æ—¶è¾“å‡ºä¸­...)",
                "Q&A": "æ­£åœ¨è¿›è¡Œ Q&A (å®æ—¶è¾“å‡ºä¸­...)",
                "Quiz": "æ­£åœ¨ç”Ÿæˆæµ‹éªŒ (å®æ—¶è¾“å‡ºä¸­...)"
            }
            st.subheader(processing_headers.get(query_option, "æ­£åœ¨å¤„ç†..."))
            st.info(f"å½“å‰ç”Ÿæˆæ¨¡å¼: **{query_option}**")
            if provider_key == "local":
                 st.info(f"å½“å‰æœ¬åœ°æ¨¡å‹: **{local_model_selection}**")
            
            classification_display = st.empty()
            llm_output_container = st.empty()
            full_llm_response = ""
            final_result_path = None
            processing_has_failed = False
            temp_dir = "temp_uploads"
            if not os.path.exists(temp_dir):
                os.makedirs(temp_dir)
            temp_file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(temp_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            generator = main_process_generator(
                input_path=temp_file_path, 
                openai_api_key=openai_api_key, 
                dify_api_key=DIFY_API_KEY, 
                output_filename=output_filename, 
                query=query_option,
                transcription_provider=provider_key,
                local_model_selection=local_model_selection,
                output_chinese_format=format_key
            )
            for event_type, value, *rest in generator:
                text = rest[0] if rest else ""
                if event_type == "progress":
                    main_progress_bar.progress(float(value))
                    main_progress_text.info(text)
                elif event_type == "sub_progress":
                    sub_progress_bar.progress(float(value))
                    sub_progress_text.text(text)
                elif event_type == "display_classification":
                    classification_display.success(f"âœ… **ç¬”è®°åˆ†ç±»**: {value}")
                elif event_type == "llm_chunk":
                    full_llm_response += value
                    llm_output_container.markdown(full_llm_response + " â–Œ")
                elif event_type == "persistent_error":
                    st.error(f"å¤„ç†å¤±è´¥: {text}")
                    main_progress_text.error("ä¸€ä¸ªå…³é”®æ­¥éª¤åœ¨å¤šæ¬¡é‡è¯•åä»ç„¶å¤±è´¥ï¼Œå·²åœæ­¢å¤„ç†ã€‚")
                    llm_output_container.error(f"**é”™è¯¯è¯¦æƒ…:**\n\n{text}")
                    if st.button("ğŸ”„ é‡æ–°å¼€å§‹"):
                        st.experimental_rerun()
                    processing_has_failed = True
                    break
                elif event_type == "error":
                    st.error(text)
                    llm_output_container.error(text)
                    processing_has_failed = True
                    break
                elif event_type == "done":
                    main_progress_bar.progress(1.0)
                    sub_progress_bar.empty()
                    sub_progress_text.empty()
                    llm_output_container.markdown(full_llm_response)
                    st.success(text)
                    final_result_path = value
            
            if final_result_path and os.path.exists(final_result_path) and not processing_has_failed:
                st.download_button(
                    label=f"ä¸‹è½½ç»“æœ ({os.path.basename(final_result_path)})",
                    data=full_llm_response,
                    file_name=os.path.basename(final_result_path),
                    mime="text/markdown",
                    use_container_width=True
                )
            
            if not keep_temp_files:
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir, ignore_errors=True)
                
                transcript_dir = "ä¸­é—´æ–‡ä»¶"
                if os.path.exists(transcript_dir):
                    shutil.rmtree(transcript_dir, ignore_errors=True)
                
                chunk_dir = "output_chunks"
                if os.path.exists(chunk_dir):
                    shutil.rmtree(chunk_dir, ignore_errors=True)
            else:
                st.info("å·²æ ¹æ®æ‚¨çš„è®¾ç½®ï¼Œä¿ç•™äº†æ‰€æœ‰ä¸­é—´æ–‡ä»¶ã€‚")