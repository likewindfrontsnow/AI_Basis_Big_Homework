# app.py
import streamlit as st
import os
from main import main_process_generator
from config import DIFY_API_KEY # Dify Key ä»ç„¶ä»é…ç½®ä¸­è¯»å–

# --- Streamlit ç•Œé¢å¸ƒå±€ ---
st.set_page_config(page_title="æ™ºèƒ½ç¬”è®° Agent", layout="wide")
st.title("ğŸ‘¨â€ğŸ’» æ™ºèƒ½ç¬”è®°ç”Ÿæˆ Agent")
st.markdown("ä¸Šä¼ æ‚¨çš„è§†é¢‘ã€éŸ³é¢‘æˆ–æ–‡æœ¬æ–‡æ¡£ï¼Œå³å¯è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–ç¬”è®°ã€‚")

# --- ç”¨æˆ·è¾“å…¥åŒºåŸŸ ---
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°é…ç½®")
    
    openai_api_key = st.text_input("è¯·è¾“å…¥æ‚¨çš„ OpenAI API Key", type="password", help="æ‚¨çš„å¯†é’¥å°†ä»…ç”¨äºæœ¬æ¬¡å¤„ç†ï¼Œä¸ä¼šè¢«ä¿å­˜ã€‚")
    output_filename = st.text_input("è¯·è¾“å…¥å¸Œæœ›çš„ç¬”è®°æ–‡ä»¶å (æ— éœ€åç¼€)", value="æˆ‘çš„å­¦ä¹ ç¬”è®°")

    st.info("è¯·åœ¨ä¸Šæ–¹é…ç½®å¥½å‚æ•°åï¼Œä¸Šä¼ æ–‡ä»¶å¼€å§‹å¤„ç†ã€‚")

# --- æ–‡ä»¶ä¸Šä¼ ä¸ä¸»é€»è¾‘ ---
uploaded_file = st.file_uploader(
    "ä¸Šä¼ è§†é¢‘ (mp4, mov, mpeg, webm)ã€éŸ³é¢‘ (mp3, m4a, wav, amr, mpga) æˆ–æ–‡æ¡£ (txt, md, mdx, markdown, pdf, html, xlsx, xls, doc, docx, csv, eml, msg, pptx, ppt, xml, epub)", 
    type=['mp4', 'mov','mpeg','webm','mp3','m4a','wav','amr','mpga','txt','md','mdx','markdown','pdf','html','xlsx','xls','doc','docx','csv','eml','msg','pptx','ppt','xml','epub']
)

if uploaded_file is not None:
    if not openai_api_key:
        st.warning("è¯·è¾“å…¥æ‚¨çš„ OpenAI API Key ä»¥ç»§ç»­ã€‚")
    else:
        if st.button("å¼€å§‹ç”Ÿæˆç¬”è®°", use_container_width=True, type="primary"):
            temp_dir = "temp_uploads"
            if not os.path.exists(temp_dir):
                os.makedirs(temp_dir)
            temp_file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(temp_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            st.markdown("---")
            st.subheader("å¤„ç†è¿›åº¦")
            
            main_progress_bar = st.progress(0)
            main_progress_text = st.empty()
            sub_progress_bar = st.progress(0)
            sub_progress_text = st.empty()

            st.markdown("---")
            st.subheader("ç”Ÿæˆç¬”è®° (å®æ—¶è¾“å‡ºä¸­...)")
            llm_output_container = st.empty()
            full_llm_response = ""
            
            final_result_path = None
            processing_has_failed = False # Flag to stop processing

            # --- å¾ªç¯è°ƒç”¨ç”Ÿæˆå™¨ï¼Œå®æ—¶æ›´æ–°UI ---
            generator = main_process_generator(temp_file_path, openai_api_key, DIFY_API_KEY, output_filename)
            for event_type, value, *rest in generator:
                text = rest[0] if rest else ""

                if event_type == "progress":
                    main_progress_bar.progress(float(value))
                    main_progress_text.info(text)
                elif event_type == "sub_progress":
                    sub_progress_bar.progress(float(value))
                    sub_progress_text.text(text)
                elif event_type == "llm_chunk":
                    full_llm_response += value
                    llm_output_container.markdown(full_llm_response + " â–Œ")
                
                # --- æ–°å¢ï¼šå¤„ç†ä¸å¯æ¢å¤çš„é”™è¯¯ ---
                elif event_type == "persistent_error":
                    st.error(f"å¤„ç†å¤±è´¥: {text}")
                    main_progress_text.error("ä¸€ä¸ªå…³é”®æ­¥éª¤åœ¨å¤šæ¬¡é‡è¯•åä»ç„¶å¤±è´¥ï¼Œå·²åœæ­¢å¤„ç†ã€‚")
                    llm_output_container.error(f"**é”™è¯¯è¯¦æƒ…:**\n\n{text}")
                    if st.button("ğŸ”„ é‡æ–°å¼€å§‹"):
                        st.experimental_rerun()
                    processing_has_failed = True
                    break # åœæ­¢å¤„ç†äº‹ä»¶
                
                # --- åŸæœ‰é”™è¯¯å¤„ç†ï¼Œç”¨äºéé‡è¯•çš„ç›´æ¥é”™è¯¯ ---
                elif event_type == "error":
                    st.error(text)
                    llm_output_container.error(text)
                    processing_has_failed = True
                    break

                elif event_type == "done":
                    main_progress_bar.progress(1.0)
                    sub_progress_bar.empty()
                    sub_progress_text.empty()
                    llm_output_container.markdown(full_llm_response)
                    st.success(text)
                    final_result_path = value # ä¿å­˜æœ€ç»ˆæ–‡ä»¶è·¯å¾„
            
            # --- æ˜¾ç¤ºæœ€ç»ˆç»“æœå’Œä¸‹è½½æŒ‰é’® ---
            if final_result_path and os.path.exists(final_result_path) and not processing_has_failed:
                st.download_button(
                    label=f"ä¸‹è½½ç¬”è®° ({os.path.basename(final_result_path)})",
                    data=full_llm_response,
                    file_name=os.path.basename(final_result_path),
                    mime="text/markdown",
                    use_container_width=True
                )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_file_path)
            except OSError as e:
                st.warning(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {e}")